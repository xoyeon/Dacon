{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lv4 튜닝 3/7 xgboost 튜닝",
      "provenance": [],
      "collapsed_sections": [
        "_h_W13Lc-p82"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xoyeon/Dacon-Daily-Python-Camp/blob/main/Lv4_%ED%8A%9C%EB%8B%9D_3_7_xgboost_%ED%8A%9C%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIpjpOEXsoW0"
      },
      "source": [
        "# [↩️ 리스트로 돌아가기](https://dacon.io/competitions/open/235698/overview/description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdkhATahdXka"
      },
      "source": [
        "# 셀을 실행할 때 팝업이 뜨면 `무시하고 계속하기` 를 눌러주세요\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91j6o0CC8y6w"
      },
      "source": [
        "## 데이터 다운로드\n",
        "---\n",
        "아래 셀을 실행시켜 데이터를 colab 에 불러옵니다.\n",
        "셀 실행은 Ctrl + Enter 를 이용해 실행시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVPJmIjs82WW",
        "outputId": "292e8128-90ee-4e8d-a951-e5021ef45497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 데이터 다운로드 링크로 데이터를 코랩에 불러옵니다.\n",
        "\n",
        "!wget 'https://bit.ly/3i4n1QB'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('3i4n1QB', 'r') as existing_zip:\n",
        "    existing_zip.extractall('data')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-06 10:07:11--  https://bit.ly/3i4n1QB\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://drive.google.com/uc?export=download&id=1emLrrpFWT8dCoj5BJb12-5QMG2-nruUw [following]\n",
            "--2021-09-06 10:07:11--  https://drive.google.com/uc?export=download&id=1emLrrpFWT8dCoj5BJb12-5QMG2-nruUw\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.128.138, 74.125.128.139, 74.125.128.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.128.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-10-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fmplvi6ec3ir6443sqrpdhh8qi2nmf0e/1630922775000/17946651057176172524/*/1emLrrpFWT8dCoj5BJb12-5QMG2-nruUw?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-09-06 10:07:12--  https://doc-10-10-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fmplvi6ec3ir6443sqrpdhh8qi2nmf0e/1630922775000/17946651057176172524/*/1emLrrpFWT8dCoj5BJb12-5QMG2-nruUw?e=download\n",
            "Resolving doc-10-10-docs.googleusercontent.com (doc-10-10-docs.googleusercontent.com)... 142.250.145.132, 2a00:1450:4013:c14::84\n",
            "Connecting to doc-10-10-docs.googleusercontent.com (doc-10-10-docs.googleusercontent.com)|142.250.145.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137694 (134K) [application/zip]\n",
            "Saving to: ‘3i4n1QB’\n",
            "\n",
            "3i4n1QB             100%[===================>] 134.47K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-09-06 10:07:13 (123 MB/s) - ‘3i4n1QB’ saved [137694/137694]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqVbFVMCGJzT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "55dce805-bd9a-4b3f-a565-eea4af3beda6"
      },
      "source": [
        "# 라이브러리 및 데이터 불러오기\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# 데이터를 불러와 학습시킬 준비하기\n",
        "\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "\n",
        "# Scailing\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train[['fixed acidity']])\n",
        "train['Scaled fixed acidity'] = scaler.transform(train[['fixed acidity']])\n",
        "test['Scaled fixed acidity'] = scaler.transform(test[['fixed acidity']])\n",
        "\n",
        "# Encoding\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(train[['type']])\n",
        "onehot = encoder.transform(train[['type']])\n",
        "onehot = onehot.toarray()\n",
        "onehot = pd.DataFrame(onehot)\n",
        "onehot.columns = encoder.get_feature_names()\n",
        "train = pd.concat([train, onehot], axis = 1)\n",
        "train = train.drop(columns = ['type'])\n",
        "\n",
        "onehot = encoder.transform(test[['type']])\n",
        "onehot = onehot.toarray()\n",
        "onehot = pd.DataFrame(onehot)\n",
        "onehot.columns = encoder.get_feature_names()\n",
        "test = pd.concat([test, onehot], axis = 1)\n",
        "test = test.drop(columns = ['type'])\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>Scaled fixed acidity</th>\n",
              "      <th>x0_red</th>\n",
              "      <th>x0_white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.48</td>\n",
              "      <td>6.6</td>\n",
              "      <td>0.043</td>\n",
              "      <td>11.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.99380</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.38</td>\n",
              "      <td>11.6</td>\n",
              "      <td>0.429752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.3</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.070</td>\n",
              "      <td>15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.00040</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.785124</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.040</td>\n",
              "      <td>44.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>0.99480</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.69</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.223140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.043</td>\n",
              "      <td>21.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>0.99480</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.280992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6.8</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.019</td>\n",
              "      <td>23.5</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.99041</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.47</td>\n",
              "      <td>11.8</td>\n",
              "      <td>0.247934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  fixed acidity  ...  x0_red  x0_white\n",
              "0      0            9.0  ...     0.0       1.0\n",
              "1      1           13.3  ...     1.0       0.0\n",
              "2      2            6.5  ...     0.0       1.0\n",
              "3      3            7.2  ...     0.0       1.0\n",
              "4      4            6.8  ...     0.0       1.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWUuPtvUZ4zO",
        "outputId": "49b973bc-a010-4f48-8ff8-e67ae30931ec"
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=6832eec64219d852fca4b58bdfe5e5182519072f497e67cfcaa504464a91aa99\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MhylK9Z7Ov"
      },
      "source": [
        "# Bayesian Optimization 불러오기\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZksEbPou52yW"
      },
      "source": [
        "## 👋 실습\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pWpHl1LdeEp"
      },
      "source": [
        "# X에 학습할 데이터를, y에 목표 변수를 저장해주세요\n",
        "X = train.drop(columns=['index','quality'])\n",
        "y = train['quality']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxijPn5Gd09b"
      },
      "source": [
        "# XGBoost의 하이퍼 파라미터의 범위를 dictionary 형태로 지정해주세요\n",
        "## Key는 XGBoost hyperparameter이름이고, value는 탐색할 범위 입니다.\n",
        "xgb_parameter_bounds = {\n",
        "                      'gamma' : (0,10),\n",
        "                      'max_depth' : (1,3), # 나무의 깊이\n",
        "                      'subsample' : (0.5,1)\n",
        "                      }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtBX2GJ-jqf"
      },
      "source": [
        "# 함수를 만들어주겠습니다.\n",
        "# 함수의 구성은 다음과 같습니다.\n",
        "# 1. 함수에 들어가는 인자 = 위에서 만든 함수의 key값들\n",
        "# 2. 함수 속 인자를 통해 받아와 새롭게 하이퍼파라미터 딕셔너리 생성\n",
        "# 3. 그 딕셔너리를 바탕으로 모델 생성\n",
        "# 4. train_test_split을 통해 데이터 train-valid 나누기\n",
        "# 5 .모델 학습\n",
        "# 6. 모델 성능 측정\n",
        "# 7. 모델의 점수 반환\n",
        "def xgb_bo(gamma,max_depth, subsample):\n",
        "\n",
        "  xgb_params = {\n",
        "              'gamma' : int(round(gamma)),\n",
        "              'max_depth' : int(round(max_depth)),\n",
        "               'subsample' : int(round(subsample)),      \n",
        "              }\n",
        "\n",
        "  xgb = XGBClassifier(**xgb_params)\n",
        "\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size = 0.2, )\n",
        "\n",
        "  xgb.fit(X_train,y_train)\n",
        "  score = accuracy_score(y_valid, xgb.predict(X_valid))\n",
        "\n",
        "  return score"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYn-_DQIxLcK"
      },
      "source": [
        "# 이제 Bayesian Optimization을 사용할 준비가 끝났습니다.\n",
        "# \"BO_xgb\"라는 변수에 Bayesian Optmization을 저장해보세요\n",
        "BO_xgb = BayesianOptimization(f = xgb_bo, pbounds = xgb_parameter_bounds,random_state = 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAX1paSYeB2i",
        "outputId": "7cd1645f-bbeb-4617-b459-6b196ad6b61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# predict 메소드와 test_one 데이터를 이용해 품질 예측\n",
        "BO_xgb.maximize(init_points = 5, n_iter = 5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |   gamma   | max_depth | subsample |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5673  \u001b[0m | \u001b[0m 5.488   \u001b[0m | \u001b[0m 2.43    \u001b[0m | \u001b[0m 0.8014  \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5491  \u001b[0m | \u001b[0m 5.449   \u001b[0m | \u001b[0m 1.847   \u001b[0m | \u001b[0m 0.8229  \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5664  \u001b[0m | \u001b[0m 4.376   \u001b[0m | \u001b[0m 2.784   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 3.834   \u001b[0m | \u001b[0m 2.583   \u001b[0m | \u001b[0m 0.7644  \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 5.68    \u001b[0m | \u001b[0m 2.851   \u001b[0m | \u001b[0m 0.5355  \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5427  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5382  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.5927  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5364  \u001b[0m | \u001b[0m 7.831   \u001b[0m | \u001b[0m 2.493   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "=============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6da0jxdq7tRU",
        "outputId": "e74774aa-b795-47b0-fb7e-116610253f30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Bayesian Optimization을 실행해보세요\n",
        "xgb_tune =XGBClassifier(gamma = 4.376,max_depth = 3, subsample = 0.9818)\n",
        "xgb_tune.fit(X,y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=4.376,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=0.9818, verbosity=1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZaDFC6eP5a"
      },
      "source": [
        "# 튜닝된 파라미터를 바탕으로 test 데이터 셋 예측\n",
        "pred = xgb_tune.predict(test.drop(columns = ['index'] ))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoRUZ71Mpc7W"
      },
      "source": [
        "#정답파일 내보내기\n",
        "\n",
        "sub = pd.read_csv('data/sample_submission.csv')\n",
        "sub['quality'] = pred\n",
        "sub.to_csv('tune_xgb.csv',index = False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h_W13Lc-p82"
      },
      "source": [
        "## 정답"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t_ufLI3eUd_"
      },
      "source": [
        "# X에 학습할 데이터를, y에 목표 변수를 저장해주세요\n",
        "X = train.drop(columns = ['index', 'quality'])\n",
        "y = train['quality']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7wkMX2PeuSW"
      },
      "source": [
        "# XGBoost의 하이퍼 파라미터의 범위를 dictionary 형태로 지정해주세요\n",
        "## Key는 XGBoost hyperparameter이름이고, value는 탐색할 범위 입니다.\n",
        "xgb_parameter_bounds = {\n",
        "                      'gamma' : (0,10),\n",
        "                      'max_depth' : (1,3), # 나무의 깊이\n",
        "                      'subsample' : (0.5,1)\n",
        "                      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDHWsdYI_mL0"
      },
      "source": [
        "# 함수를 만들어주겠습니다.\n",
        "# 함수의 구성은 다음과 같습니다.\n",
        "# 1. 함수에 들어가는 인자 = 위에서 만든 함수의 key값들\n",
        "# 2. 함수 속 인자를 통해 받아와 새롭게 하이퍼파라미터 딕셔너리 생성\n",
        "# 3. 그 딕셔너리를 바탕으로 모델 생성\n",
        "# 4. train_test_split을 통해 데이터 train-valid 나누기\n",
        "# 5 .모델 학습\n",
        "# 6. 모델 성능 측정\n",
        "# 7. 모델의 점수 반환\n",
        "\n",
        "def xgb_bo(gamma,max_depth, subsample):\n",
        "  xgb_params = {\n",
        "              'gamma' : int(round(gamma)),\n",
        "              'max_depth' : int(round(max_depth)),\n",
        "               'subsample' : int(round(subsample)),      \n",
        "              }\n",
        "  xgb = XGBClassifier(**xgb_params)\n",
        "\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size = 0.2, )\n",
        "\n",
        "  xgb.fit(X_train,y_train)\n",
        "  score = accuracy_score(y_valid, xgb.predict(X_valid))\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV9oZAH9euE-"
      },
      "source": [
        "# 이제 Bayesian Optimization을 사용할 준비가 끝났습니다.\n",
        "# \"BO_xgb\"라는 변수에 Bayesian Optmization을 저장해보세요\n",
        "BO_xgb = BayesianOptimization(f = xgb_bo, pbounds = xgb_parameter_bounds,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2uPU3wKet_z"
      },
      "source": [
        "# Bayesian Optimization을 실행해보세요\n",
        "BO_xgb.maximize(init_points = 5, n_iter = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHjIBUnVet55"
      },
      "source": [
        "# 튜닝된 파라미터를 바탕으로 test 데이터 셋 예측\n",
        "\n",
        "#학습\n",
        "xgb_tune =XGBClassifier(gamma = 4.376,max_depth = 3, subsample = 0.9818)\n",
        "xgb_tune.fit(X,y)\n",
        "\n",
        "\n",
        "#예측\n",
        "pred = xgb_tune.predict(test.drop(columns = ['index'] ))\n",
        "\n",
        "#정답파일 내보내기\n",
        "sub = pd.read_csv('data/sample_submission.csv')\n",
        "sub['quality'] = pred\n",
        "sub.to_csv('tune_xgb.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8YgC54VtiB7"
      },
      "source": [
        "# [↩️ 리스트로 돌아가기](https://dacon.io/competitions/open/235698/overview/description)"
      ]
    }
  ]
}